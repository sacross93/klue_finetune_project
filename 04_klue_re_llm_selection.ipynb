{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KLUE Relation Extraction - LLM 선정 근거\n",
    "\n",
    "이 노트북은 **왜 인코더 기반 모델을 선택했는지**, 그리고 **인코더 중 KLUE-RoBERTa base를 선택한 이유**를 정리합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 왜 인코더 기반 모델을 선택했는가?\n",
    "\n",
    "### 1) 문제 특성에 적합\n",
    "- KLUE RE는 **고정 라벨(30개) 분류** 문제\n",
    "- 인코더는 입력 문장을 **전체적으로 이해한 후 분류 헤드로 라벨 예측**하기에 적합\n",
    "\n",
    "### 2) 효율성과 재현성\n",
    "- 디코더 기반 LLM은 프롬프트 설계/출력 안정성에 변수가 큼\n",
    "- 인코더는 학습/평가 흐름이 표준화되어 **재현성이 높고 비교가 용이**\n",
    "\n",
    "### 3) 리소스와 개발 속도\n",
    "- 인코더 + 분류헤드는 상대적으로 가볍고 학습 속도가 빠름\n",
    "- 실험 반복(베이스라인 → 개선) 구조에 유리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 왜 KLUE-RoBERTa base를 선택했는가?\n",
    "\n",
    "### 1) 한국어 NLU에 최적화된 사전학습 모델\n",
    "- KLUE 벤치마크에 맞춰 설계된 한국어 인코더 모델\n",
    "- KLUE RE 태스크와 **도메인/언어 정합성**이 높음\n",
    "\n",
    "### 2) small/large 대비 균형점\n",
    "- **small**: 파라미터가 작아 학습은 빠르지만, 복잡한 관계 패턴을 학습하기엔 표현력이 부족할 수 있음\n",
    "- **large**: 성능 잠재력은 높지만, 학습 비용(시간/메모리)이 급증하고 과적합 위험이 커짐\n",
    "- **base**: 성능/비용의 균형점. 과제 수행과 실험 반복에 가장 현실적인 선택\n",
    "\n",
    "### 3) 데이터 규모와의 적합성\n",
    "- 학습 데이터 3만 샘플 규모는 **base 모델이 안정적으로 학습하기 좋은 크기**\n",
    "- large 사용 시 성능 상승 대비 비용 증가가 클 수 있음\n",
    "\n",
    "### 4) 이후 확장성\n",
    "- base로 베이스라인 구축 후, 성능 개선 단계에서 large로 확장하는 전략이 명확함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 고려했으나 제외한 대안 (임베딩 모델)\n",
    "\n",
    "### Qwen3 Embedding 8B 검토\n",
    "- ko-embedding-leaderboard 기준 한국어 성능이 높은 임베딩 모델이어서 대안으로 검토함. (https://github.com/OnAnd0n/ko-embedding-leaderboard)\n",
    "- 그러나 본 과제는 **고정 라벨(30개) 분류** 문제로, 임베딩 모델은 **유사도/검색 최적화** 목적이라 태스크 적합성이 떨어짐.\n",
    "- 임베딩 모델을 사용할 경우 **벡터 추출 후 별도 분류기(MLP/Linear) 학습**이 필요해 파이프라인이 복잡해짐.\n",
    "- 8B 모델은 **메모리/추론 비용이 큼** → 과제 환경에서 반복 실험에 비효율적.\n",
    "- 따라서 **RE 분류에 직접 최적화된 인코더(PLM) + 분류 헤드 구조**가 더 합리적이라고 판단함.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 최종 선택 요약\n",
    "- **모델 유형**: 인코더 기반 (분류 문제에 최적)\n",
    "- **모델 크기**: KLUE-RoBERTa base\n",
    "- **선택 이유**: 성능/비용 균형, 한국어 최적화, 실험 반복에 유리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KLUE RE는 고정 라벨 분류 문제이므로 안정적 분류 성능과 재현성을 제공하는 인코더 기반 모델이 적합하며, KLUE-RoBERTa base는 성능과 학습 비용의 균형이 가장 좋다.\n"
     ]
    }
   ],
   "source": [
    "summary = \"KLUE RE는 고정 라벨 분류 문제이므로 안정적 분류 성능과 재현성을 제공하는 인코더 기반 모델이 적합하며, KLUE-RoBERTa base는 성능과 학습 비용의 균형이 가장 좋다.\"\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
