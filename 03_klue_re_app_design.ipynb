{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KLUE Relation Extraction - 어플리케이션 구조 설계\n",
    "\n",
    "이 노트북은 **데이터 → 전처리 → 학습 → 평가 → 추론**까지의 전체 흐름과 모듈 구성을 설계합니다.\n",
    "LLM 선택은 다음 단계에서 진행합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 목표 및 범위\n",
    "- KLUE RE 데이터셋 기반 관계 분류 태스크\n",
    "- 고정 라벨(30개) 분류 문제\n",
    "- 학습/평가/추론 파이프라인을 일관된 구조로 설계"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 시스템 개요(High-Level)\n",
    "\n",
    "```\n",
    "Raw CSV\n",
    "  │\n",
    "  ├─ Data Loader\n",
    "  │     └─ Schema Validation\n",
    "  │\n",
    "  ├─ Preprocess / Feature Builder\n",
    "  │     └─ Entity Marker Insertion\n",
    "  │\n",
    "  ├─ Model\n",
    "  │     └─ Encoder + Classification Head\n",
    "  │\n",
    "  ├─ Train / Eval\n",
    "  │     └─ Metrics (Macro F1, Micro F1)\n",
    "  │\n",
    "  └─ Inference\n",
    "        └─ Text + Entities → Relation Label\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 모듈 구성\n",
    "\n",
    "### 3.1 Data Layer\n",
    "- 입력: `sentence`, `subject_entity`, `object_entity`, `label`, `source`\n",
    "- 역할: 데이터 로드, 스키마 확인, train/valid 분리 확인\n",
    "\n",
    "### 3.2 Preprocess Layer\n",
    "- 엔티티 span 검증\n",
    "- 입력 포맷 생성(예: `[SUBJ]...[/SUBJ]`, `[OBJ]...[/OBJ]`)\n",
    "- 라벨 매핑(id ↔ label)\n",
    "\n",
    "### 3.3 Model Layer\n",
    "- 입력 텍스트 → 토크나이즈 → 인코더 → 분류 헤드\n",
    "- 모델 구조는 LLM 선정 단계에서 확정\n",
    "\n",
    "### 3.4 Train/Eval Layer\n",
    "- Loss: Cross Entropy\n",
    "- Metric: Macro F1 중심(클래스 불균형 고려)\n",
    "- 체크포인트/로그 관리\n",
    "\n",
    "### 3.5 Inference Layer\n",
    "- 입력: 문장 + 엔티티 정보\n",
    "- 동일 전처리 적용 후 라벨 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 데이터 흐름 설계\n",
    "\n",
    "### 입력 → 전처리 → 학습\n",
    "1) CSV 로드\n",
    "2) 엔티티 파싱 및 span 검증\n",
    "3) 입력 포맷 변환(마커 삽입)\n",
    "4) 라벨 매핑\n",
    "5) 학습/평가\n",
    "\n",
    "### 추론\n",
    "1) 사용자 입력 문장 + 엔티티 정보 수집\n",
    "2) 동일 전처리 적용\n",
    "3) 모델 예측 → 라벨 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 입출력 정의\n",
    "\n",
    "### 학습 입력\n",
    "- `input_text`: 엔티티 마킹된 문장\n",
    "- `label_id`: 정수 라벨\n",
    "\n",
    "### 추론 입력\n",
    "- `sentence`\n",
    "- `subject_entity` (word, start_idx, end_idx, type)\n",
    "- `object_entity` (word, start_idx, end_idx, type)\n",
    "\n",
    "### 추론 출력\n",
    "- `pred_label`\n",
    "- (optional) `confidence`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 전처리 규칙(요약)\n",
    "- 엔티티 span은 문장과 정확히 일치해야 함\n",
    "- 마커 삽입 시 뒤에서부터 처리하여 인덱스 꼬임 방지\n",
    "- 라벨 매핑은 고정(0~29)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 로깅/재현성\n",
    "- Seed 고정\n",
    "- 실험 설정(config) 기록\n",
    "- 학습 로그 저장 (metric, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 리스크 및 대응\n",
    "- **클래스 불균형**: macro F1 기준 평가, 추후 가중치/샘플링 도입\n",
    "- **중복 샘플 존재**: 필요 시 중복 제거/하향 가중치\n",
    "- **긴 문장**: 토큰 길이 제한 고려(Truncation 전략)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 다음 단계\n",
    "- LLM 후보 비교 및 선정\n",
    "- 모델 세부 구조 확정\n",
    "- 베이스라인 학습 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이프라인 설정 예시\n",
    "config = {\n",
    "    \"seed\": 42,\n",
    "    \"max_length\": 256,\n",
    "    \"batch_size\": 16,\n",
    "    \"lr\": 2e-5,\n",
    "    \"epochs\": 3,\n",
    "    \"metric\": \"macro_f1\",\n",
    "}\n",
    "print(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
