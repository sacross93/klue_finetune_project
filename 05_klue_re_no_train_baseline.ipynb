{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KLUE Relation Extraction - 학습 전 베이스라인 평가\n",
    "\n",
    "이 노트북은 **학습 없이** 얻을 수 있는 기준 성능을 확인합니다.\n",
    "- 다수 클래스(majority) 예측\n",
    "- 랜덤 예측 (균등/분포 기반)\n",
    "\n",
    "결과는 파인튜닝 이후 성능과 비교하는 기준점으로 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Seed fixed: 42\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# 재현성\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "print(f\"✅ Seed fixed: {SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 결과 저장 디렉터리 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 결과 저장 경로: temp_result/05_klue_re_no_train_baseline\n"
     ]
    }
   ],
   "source": [
    "NOTEBOOK_NAME = \"05_klue_re_no_train_baseline\"\n",
    "RESULT_DIR = Path(\"temp_result\") / NOTEBOOK_NAME\n",
    "RESULT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def _to_builtin(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        converted = {}\n",
    "        for k, v in obj.items():\n",
    "            kk = k\n",
    "            try:\n",
    "                kk = kk.item()\n",
    "            except Exception:\n",
    "                pass\n",
    "            if isinstance(kk, (dict, list, tuple)):\n",
    "                kk = str(kk)\n",
    "            converted[kk] = _to_builtin(v)\n",
    "        return converted\n",
    "    if isinstance(obj, (list, tuple)):\n",
    "        return [_to_builtin(v) for v in obj]\n",
    "    try:\n",
    "        return obj.item()\n",
    "    except Exception:\n",
    "        return obj\n",
    "\n",
    "\n",
    "def save_json(filename, obj):\n",
    "    path = RESULT_DIR / filename\n",
    "    path.write_text(json.dumps(_to_builtin(obj), ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "    return path\n",
    "\n",
    "print(f\"✅ 결과 저장 경로: {RESULT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 32,470 / Valid: 7,765\n",
      "컬럼: ['guid', 'sentence', 'subject_entity', 'object_entity', 'label', 'source']\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/klue_re_train.csv')\n",
    "valid_df = pd.read_csv('data/klue_re_validation.csv')\n",
    "\n",
    "print(f\"Train: {len(train_df):,} / Valid: {len(valid_df):,}\")\n",
    "print(\"컬럼:\", train_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 평가 지표 정의\n",
    "- Accuracy\n",
    "- Macro F1\n",
    "- Micro F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "\n",
    "def eval_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"accuracy\": float(accuracy_score(y_true, y_pred)),\n",
    "        \"macro_f1\": float(f1_score(y_true, y_pred, average='macro')),\n",
    "        \"micro_f1\": float(f1_score(y_true, y_pred, average='micro')),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 베이스라인 1: 다수 클래스(majority) 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority label: 0\n",
      "{'accuracy': 0.5963940759819704, 'macro_f1': 0.024905883618371517, 'micro_f1': 0.5963940759819704}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('temp_result/05_klue_re_no_train_baseline/baseline_majority.json')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "major_label = train_df['label'].value_counts().idxmax()\n",
    "\n",
    "valid_pred_major = np.full(len(valid_df), major_label)\n",
    "metrics_major = eval_metrics(valid_df['label'], valid_pred_major)\n",
    "\n",
    "print(\"Majority label:\", major_label)\n",
    "print(metrics_major)\n",
    "\n",
    "save_json(\"baseline_majority.json\", {\n",
    "    \"major_label\": int(major_label),\n",
    "    \"metrics\": metrics_major\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 베이스라인 2: 랜덤 예측 (균등 분포)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.03193818415969092, 'macro_f1': 0.016523317185787874, 'micro_f1': 0.03193818415969092}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('temp_result/05_klue_re_no_train_baseline/baseline_random_uniform.json')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = sorted(train_df['label'].unique())\n",
    "valid_pred_uniform = np.random.choice(labels, size=len(valid_df), replace=True)\n",
    "metrics_uniform = eval_metrics(valid_df['label'], valid_pred_uniform)\n",
    "\n",
    "print(metrics_uniform)\n",
    "\n",
    "save_json(\"baseline_random_uniform.json\", {\n",
    "    \"metrics\": metrics_uniform\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 베이스라인 3: 랜덤 예측 (학습 분포 기반)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.19523502897617515, 'macro_f1': 0.028611222209651697, 'micro_f1': 0.19523502897617515}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('temp_result/05_klue_re_no_train_baseline/baseline_random_weighted.json')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts = train_df['label'].value_counts().sort_index()\n",
    "probs = label_counts.values / label_counts.values.sum()\n",
    "\n",
    "valid_pred_weighted = np.random.choice(label_counts.index, size=len(valid_df), replace=True, p=probs)\n",
    "metrics_weighted = eval_metrics(valid_df['label'], valid_pred_weighted)\n",
    "\n",
    "print(metrics_weighted)\n",
    "\n",
    "save_json(\"baseline_random_weighted.json\", {\n",
    "    \"metrics\": metrics_weighted\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 요약\n",
    "- 학습 없이 얻은 기준 성능을 기록함\n",
    "- 이후 파인튜닝 성능과 비교하여 학습 효과를 검증할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b00820",
   "metadata": {},
   "source": [
    "- **다수 클래스(majority) 예측**은 accuracy/micro F1 **0.596**으로 가장 높지만, **macro F1 0.0249**로 거의 학습이 없는 수준임. 이는 **no_relation 비중이 큰 클래스 불균형** 때문에 생기는 착시임.\n",
    "- **균등 랜덤 예측**은 accuracy/micro F1 **0.0319**, macro F1 **0.0165**로 사실상 의미 없는 기준선.\n",
    "- **분포 기반 랜덤 예측**은 accuracy/micro F1 **0.195**, macro F1 **0.0286**으로 약간 개선되나, 여전히 모든 관계를 균형 있게 맞추지 못함.\n",
    "- 결론적으로 KLUE-RE는 **macro F1 중심 평가가 필수**이며, 이후 학습/개선 단계에서는 **소수 클래스 성능 향상**이 핵심 과제가 됨."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
